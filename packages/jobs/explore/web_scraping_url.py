import json
import logging
from playwright.sync_api import sync_playwright

# Setup de log
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def iniciar_json():
    with open("aneel_datasets_completos.json", "w", encoding="utf-8") as f:
        f.write("[\n")

def salvar_json_incremental(dado, primeira_vez=False):
    with open("aneel_datasets_completos.json", "a", encoding="utf-8") as f:
        if not primeira_vez:
            f.write(",\n")
        json.dump(dado, f, indent=2, ensure_ascii=False)

def finalizar_json():
    with open("aneel_datasets_completos.json", "a", encoding="utf-8") as f:
        f.write("\n]")

# üîÑ Rola e clica no bot√£o "Mais resultados"
def carregar_todos_os_resultados(page):
    try:
        logging.info("üîΩ Rolando at√© o final da p√°gina para revelar o bot√£o...")
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        page.wait_for_timeout(2000)

        logging.info("üîò Buscando e clicando no bot√£o 'Mais resultados'...")
        encontrou = page.evaluate("""
            () => {
                const allButtons = Array.from(document.querySelectorAll('calcite-button'));
                for (const btn of allButtons) {
                    const shadowBtn = btn.shadowRoot?.querySelector('button');
                    if (shadowBtn && shadowBtn.textContent.includes("Mais resultados") && !shadowBtn.disabled) {
                        shadowBtn.click();
                        return true;
                    }
                }
                return false;
            }
        """)
        if encontrou:
            logging.info("‚úÖ Clique no bot√£o 'Mais resultados' realizado com sucesso.")
            page.wait_for_timeout(4000)
        else:
            logging.warning("‚ö†Ô∏è Bot√£o 'Mais resultados' n√£o encontrado ou desabilitado.")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Erro ao tentar clicar no bot√£o: {e}")

    try:
        logging.info("üîΩ Rolando at√© o final da p√°gina para revelar o bot√£o...")
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        page.wait_for_timeout(2000)

        logging.info("üîò Aguardando bot√£o 'Mais resultados' aparecer...")
        page.wait_for_selector("calcite-button", timeout=5000)

        logging.info("üñ±Ô∏è Clicando no bot√£o 'Mais resultados'...")
        page.evaluate("""
            () => {
                const calciteButton = document.querySelector('calcite-button');
                const shadowRoot = calciteButton?.shadowRoot;
                const button = shadowRoot?.querySelector('button');

                if (button && !button.disabled && button.getAttribute('aria-disabled') !== 'true') {
                    button.click();
                }
            }
        """)
        logging.info("‚úÖ Clique realizado com sucesso.")
        page.wait_for_timeout(4000)  # tempo para carregar nova p√°gina
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Erro ao clicar no bot√£o: {e}")

# üîç Extrai links dos cards e salva item por item
def extract_dataset_links(page):
    links_extraidos = []
    primeira_vez_flag = True

    try:
        page.wait_for_selector("li arcgis-hub-entity-card", timeout=10000)
        list_items = page.query_selector_all("li")

        for index, li in enumerate(list_items):
            if index >= 24:
                logging.info("‚õî Limite de 24 registros atingido.")
                break
            try:
                link_element = li.query_selector("h3.title a")
                if link_element:
                    titulo = link_element.inner_text().strip()
                    href = link_element.get_attribute("href")

                    if href and href.startswith("/datasets/"):
                        dataset_id = href.split("/")[2]
                        url_about = f"https://dadosabertos-aneel.opendata.arcgis.com{href}/about"
                        url_download = f"https://www.arcgis.com/sharing/rest/content/items/{dataset_id}/data"

                        dado = {
                            "titulo": titulo,
                            "url": url_about,
                            "id": dataset_id,
                            "download": url_download
                        }

                        salvar_json_incremental(dado, primeira_vez_flag)
                        primeira_vez_flag = False
                        logging.info(f"üìù Salvando no JSON: {dado['titulo']}")
                        links_extraidos.append(dado)

            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Erro ao processar <li>: {e}")

    except Exception as e:
        logging.error(f"‚ùå Falha ao extrair os links: {e}")

    return links_extraidos

# üß© Fun√ß√£o principal
def scrape_aneel_all_datasets():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(accept_downloads=False)
        page = context.new_page()

        url = "https://dadosabertos-aneel.opendata.arcgis.com/search?tags=distribuicao"
        page.goto(url)
        page.wait_for_timeout(4000)

        iniciar_json()
        carregar_todos_os_resultados(page)
        links = extract_dataset_links(page)
        finalizar_json()

        print(f"Total de registros extra√≠dos: {len(links)}")
        browser.close()

        logging.info(f"‚úÖ Total de datasets salvos: {len(links)}")
        logging.info("üìÅ Arquivo salvo: aneel_datasets_completos.json")

# üöÄ Executa o scraper
scrape_aneel_all_datasets()
